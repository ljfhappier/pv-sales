{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = 'data/'\n",
    "train_sales  = pd.read_csv(path+'train_sales_data.csv') #历史销量数据\n",
    "train_search = pd.read_csv(path+'train_search_data.csv') # 省 车型 年 月 搜索量\n",
    "train_user   = pd.read_csv(path+'train_user_reply_data.csv') # 车型 年月 评价数量\n",
    "evaluation_public = pd.read_csv(path+'evaluation_public.csv') # 待预测数据\n",
    "submit_example    = pd.read_csv(path+'submit_example.csv') # 提交格式\n",
    "data = pd.concat([train_sales, evaluation_public], ignore_index=True) # 历史销量数据  带预测数据 合并\n",
    "data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth']) # merge 搜索量\n",
    "data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth']) # merge 评价数量\n",
    "data['label'] = data['salesVolume'] # 添加列，y值\n",
    "data['id'] = data['id'].fillna(0).astype(int) #？不知道干什么用|id=0的数据市train data,大于0的test data\n",
    "# fillna evaluation_data中bodyType的缺失值\n",
    "data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType']) \n",
    "#LabelEncoder\n",
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth'] # 从 201601起，开始月份计数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpdf=pd.read_csv(path+'GDP_OF_PROVINCE.txt',encoding='gb18030',sep='\\t')\n",
    "month_to_quater_dict={1:'A',2:'A',3:'A',4:'B',5:'B',6:'B',7:'C',8:'C',9:'C',10:'D',11:'D',12:'D'}\n",
    "gdpdf['gdp_key']=gdpdf['short_of_province']+'_'+gdpdf['quarter']\n",
    "data['gdp_key']=data.province+'_'+data.regYear.map(str)+data.regMonth.map(month_to_quater_dict)\n",
    "gdpdict=gdpdf.set_index('gdp_key',inplace=False)['gdp'].drop_duplicates()\n",
    "data['gdp']=data['gdp_key'].map(gdpdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "dateindex=gdpdf.quarter.map(lambda x:True if not re.match('2008\\w',x) else False)\n",
    "gdpdf=gdpdf[dateindex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales,popularity,carCommentVolum,newsReplyVolum 历史数据平移 匹配\n",
    "def get_stat_feature(df_):   \n",
    "    df = df_.copy()# 复制，不改变原始的df\n",
    "    stat_feat = [] # 列表容器，保存？平移 月份 feature\n",
    "    df['model_adcode'] = df['adcode'] + df['model'] # 构造组合字段\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt'] # 月份 平移 key\n",
    "    for col in tqdm(['label','popularity','carCommentVolum','newsReplyVolum']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i)) # 迁移 月份feature append\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i # 构造 平移 i月 后的datetime index\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i)) # 筛选非空，列设置为index\n",
    "            # 构造 平移i月 对应列的 sale数量\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])  \n",
    "    for col in tqdm(['gdp']):\n",
    "        # shift\n",
    "        #for i in [3,6,9,12]:\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i)) # 迁移 月份feature append\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i # 构造 平移 i月 后的datetime index\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i)) # 筛选非空，列设置为index\n",
    "            # 构造 平移i月 对应列的 sale数量\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])             \n",
    "    return df,stat_feat # 返回 feature enginering 后的表，构造的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics 评价指标\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int) # 负值取0\n",
    "    # 数据分组聚合\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index() # list ? 什么功能\n",
    "    \n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns] # 重命名列名称\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "    #return data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建 实例化 train ，返回 训练后的模型 \n",
    "# 调参\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**4-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2019,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              categorical_feature=cate_feat, \n",
    "              early_stopping_rounds=100, verbose=100)      \n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用历史销量数据，训练模型\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy() # 表复制，保留原表格式\n",
    "    # 数据集划分\n",
    "    st = 13 \n",
    "    all_idx   = (df['mt'].between(st , m-1)) \n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )  \n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']   \n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)  # train_data,得到 model\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features]) # 预测值\n",
    "    best_score = score(df[valid_idx])  # 评分\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat) # 全量数据 train + valid\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label']) # 全量数据\n",
    "    df['forecastVolum'] = model.predict(df[features]) \n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)  # test data \n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 65\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 11951.4\tvalid_1's l2: 38301.9\n",
      "[200]\ttraining's l2: 7341.97\tvalid_1's l2: 35244.3\n",
      "[300]\ttraining's l2: 5470.19\tvalid_1's l2: 34480.6\n",
      "[400]\ttraining's l2: 4211.15\tvalid_1's l2: 33902\n",
      "[500]\ttraining's l2: 3404.53\tvalid_1's l2: 33881.8\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's l2: 4089.43\tvalid_1's l2: 33853\n",
      "0.7557607876297023\n",
      "valid mean: 605.798341661586\n",
      "true  mean: 649.3121212121212\n",
      "test  mean: 481.38768786783226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 65\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 12664.7\tvalid_1's l2: 43924.7\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's l2: 19562.8\tvalid_1's l2: 41866.3\n",
      "0.7275750274621948\n",
      "valid mean: 638.4105736561097\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 340.8852727553691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 65\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 13456.1\tvalid_1's l2: 38786.9\n",
      "[200]\ttraining's l2: 8625.4\tvalid_1's l2: 37160.3\n",
      "[300]\ttraining's l2: 6409.29\tvalid_1's l2: 37871.7\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's l2: 8524.91\tvalid_1's l2: 37017\n",
      "0.7692682707362428\n",
      "valid mean: 633.3424195920754\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 513.7030306701608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 65\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 13954\tvalid_1's l2: 263432\n",
      "[200]\ttraining's l2: 8994.03\tvalid_1's l2: 256064\n",
      "[300]\ttraining's l2: 6897.27\tvalid_1's l2: 254486\n",
      "Early stopping, best iteration is:\n",
      "[267]\ttraining's l2: 7503.48\tvalid_1's l2: 253928\n",
      "0.6077101057939049\n",
      "valid mean: 660.4519021412477\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 494.60484681970416\n"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data) # 每次都重新平移月份数据\n",
    "    \n",
    "    num_feat = ['regYear'] + stat_feat # 数值型特征 列表\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth'] # 标签型特征 列表\n",
    "    \n",
    "    if m_type == 'lgb': # lgb模型预测\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb': #xgb 模型预测\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat # 用于预测模型的特征\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "sub1 = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub1.columns = ['id','forecastVolum']\n",
    "#sub[['id','forecastVolum']].round().astype(int).to_csv('data/CCF_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 4/4 [00:02<00:00,  1.49it/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 57\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:841.375\tvalidation_1-rmse:1046.8\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:800.264\tvalidation_1-rmse:1004.59\n",
      "[200]\tvalidation_0-rmse:265.613\tvalidation_1-rmse:376.883\n",
      "[300]\tvalidation_0-rmse:148.956\tvalidation_1-rmse:247.049\n",
      "[400]\tvalidation_0-rmse:126.356\tvalidation_1-rmse:236.94\n",
      "[500]\tvalidation_0-rmse:115.943\tvalidation_1-rmse:233.142\n",
      "[600]\tvalidation_0-rmse:108.343\tvalidation_1-rmse:229.144\n",
      "[700]\tvalidation_0-rmse:101.444\tvalidation_1-rmse:226.449\n",
      "[800]\tvalidation_0-rmse:96.2101\tvalidation_1-rmse:224.598\n",
      "[900]\tvalidation_0-rmse:92.0183\tvalidation_1-rmse:223.334\n",
      "[1000]\tvalidation_0-rmse:88.2163\tvalidation_1-rmse:223.272\n",
      "[1100]\tvalidation_0-rmse:84.1205\tvalidation_1-rmse:220.246\n",
      "[1200]\tvalidation_0-rmse:80.0675\tvalidation_1-rmse:217.142\n",
      "[1300]\tvalidation_0-rmse:76.9898\tvalidation_1-rmse:215.442\n",
      "[1400]\tvalidation_0-rmse:74.6882\tvalidation_1-rmse:215.3\n",
      "[1500]\tvalidation_0-rmse:71.8755\tvalidation_1-rmse:214.071\n",
      "[1600]\tvalidation_0-rmse:69.6953\tvalidation_1-rmse:212.806\n",
      "[1700]\tvalidation_0-rmse:66.5482\tvalidation_1-rmse:212.041\n",
      "[1800]\tvalidation_0-rmse:64.1877\tvalidation_1-rmse:210.748\n",
      "[1900]\tvalidation_0-rmse:62.2822\tvalidation_1-rmse:210.594\n",
      "[1999]\tvalidation_0-rmse:60.3758\tvalidation_1-rmse:210.027\n",
      "0.7615435420144199\n",
      "valid mean: 631.9588012695312\n",
      "true  mean: 649.3121212121212\n",
      "test  mean: 455.3822937011719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 4/4 [00:02<00:00,  1.54it/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 21.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 57\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:866.608\tvalidation_1-rmse:1007.37\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:825.431\tvalidation_1-rmse:966.165\n",
      "[200]\tvalidation_0-rmse:275.251\tvalidation_1-rmse:390.807\n",
      "[300]\tvalidation_0-rmse:153.771\tvalidation_1-rmse:331.571\n",
      "[400]\tvalidation_0-rmse:129.364\tvalidation_1-rmse:313.723\n",
      "[500]\tvalidation_0-rmse:118.693\tvalidation_1-rmse:311.841\n",
      "[600]\tvalidation_0-rmse:111.694\tvalidation_1-rmse:312.13\n",
      "Stopping. Best iteration:\n",
      "[508]\tvalidation_0-rmse:118.326\tvalidation_1-rmse:311.237\n",
      "\n",
      "0.6311015753636667\n",
      "valid mean: 461.514404296875\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 295.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 4/4 [00:02<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 21.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 57\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:881.697\tvalidation_1-rmse:1071.89\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:840.514\tvalidation_1-rmse:1029.15\n",
      "[200]\tvalidation_0-rmse:283.505\tvalidation_1-rmse:381.699\n",
      "[300]\tvalidation_0-rmse:165.576\tvalidation_1-rmse:265.136\n",
      "[400]\tvalidation_0-rmse:134.53\tvalidation_1-rmse:248.204\n",
      "[500]\tvalidation_0-rmse:121.381\tvalidation_1-rmse:240.713\n",
      "[600]\tvalidation_0-rmse:113.054\tvalidation_1-rmse:236.493\n",
      "[700]\tvalidation_0-rmse:106.909\tvalidation_1-rmse:232.673\n",
      "[800]\tvalidation_0-rmse:100.834\tvalidation_1-rmse:231.166\n",
      "[900]\tvalidation_0-rmse:97.1048\tvalidation_1-rmse:230.88\n",
      "Stopping. Best iteration:\n",
      "[865]\tvalidation_0-rmse:98.3272\tvalidation_1-rmse:230.464\n",
      "\n",
      "0.7343410104694204\n",
      "valid mean: 586.1441650390625\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 345.6141662597656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 4/4 [00:02<00:00,  1.51it/s]\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 21.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 57\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:900.647\tvalidation_1-rmse:1451.3\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:859.325\tvalidation_1-rmse:1408.26\n",
      "[200]\tvalidation_0-rmse:288.848\tvalidation_1-rmse:742.565\n",
      "[300]\tvalidation_0-rmse:161.505\tvalidation_1-rmse:635.225\n",
      "[400]\tvalidation_0-rmse:132.668\tvalidation_1-rmse:630.399\n",
      "Stopping. Best iteration:\n",
      "[319]\tvalidation_0-rmse:154.589\tvalidation_1-rmse:628.549\n",
      "\n",
      "0.5114843441258969\n",
      "valid mean: 577.2192993164062\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 325.6264343261719\n"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    m_type = 'xgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "sub2 = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub2.columns = ['id','forecastVolum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predvolum=sub1['forecastVolum'] * 0.6 + sub2['forecastVolum'] * 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub3=sub1.copy()\n",
    "sub3['forecastVolum']=predvolum.round().astype(np.int)\n",
    "sub3.to_csv('data/CCF_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data=data[['province','model','bodyType','regYear','regMonth','salesVolume','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36960 entries, 0 to 36959\n",
      "Data columns (total 16 columns):\n",
      "adcode             36960 non-null int64\n",
      "bodyType           36960 non-null int64\n",
      "forecastVolum      0 non-null float64\n",
      "id                 36960 non-null int32\n",
      "model              36960 non-null int64\n",
      "province           36960 non-null object\n",
      "regMonth           36960 non-null int64\n",
      "regYear            36960 non-null int64\n",
      "salesVolume        36960 non-null float64\n",
      "popularity         31680 non-null float64\n",
      "carCommentVolum    31680 non-null float64\n",
      "newsReplyVolum     31680 non-null float64\n",
      "label              36960 non-null float64\n",
      "mt                 36960 non-null int64\n",
      "gdp_key            36960 non-null object\n",
      "gdp                36960 non-null float64\n",
      "dtypes: float64(7), int32(1), int64(6), object(2)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
